# ğŸš€ Weaviable - Sistema RAG con Weaviate y Ollama

Un sistema RAG (Retrieval-Augmented Generation) completo que permite procesar documentos PDF, almacenarlos en una base de datos vectorial y realizar consultas inteligentes usando modelos de lenguaje locales.

[![Python](https://img.shields.io/badge/python-3.11+-blue.svg)](https://www.python.org/downloads/)
[![Docker](https://img.shields.io/badge/docker-required-blue.svg)](https://www.docker.com/)
[![Ollama](https://img.shields.io/badge/ollama-local--llm-green.svg)](https://ollama.ai/)
[![Weaviate](https://img.shields.io/badge/weaviate-vector--db-orange.svg)](https://weaviate.io/)

## ğŸ“‹ Tabla de Contenidos

- [ğŸŒŸ CaracterÃ­sticas](#-caracterÃ­sticas)
- [ğŸ—ï¸ Arquitectura](#ï¸-arquitectura)
- [ğŸ“‹ Requisitos](#-requisitos)
- [âš¡ InstalaciÃ³n RÃ¡pida](#-instalaciÃ³n-rÃ¡pida)
- [ğŸš€ Uso](#-uso)
- [ğŸ“ Estructura del Proyecto](#-estructura-del-proyecto)
- [ğŸ’¡ Ejemplos de Consultas](#-ejemplos-de-consultas)
- [ğŸ”§ Troubleshooting](#-troubleshooting)
- [ğŸ“– DocumentaciÃ³n Completa](#-documentaciÃ³n-completa)

## ğŸŒŸ CaracterÃ­sticas

- ğŸ“– **Procesamiento de PDFs** - Extrae y procesa documentos automÃ¡ticamente
- ğŸ§  **Embeddings locales** - Genera vectores usando Ollama (sin APIs externas)
- ğŸ’¾ **Base de datos vectorial** - Almacena conocimiento en Weaviate local
- ğŸ” **BÃºsqueda hÃ­brida** - Combina bÃºsqueda vectorial y por texto
- ğŸ’¬ **Chat interactivo** - Interfaz de terminal para consultas naturales
- ğŸ³ **FÃ¡cil deployment** - Todo containerizado con Docker

## ğŸ—ï¸ Arquitectura

```
PDF â†’ Chunks â†’ Embeddings â†’ Weaviate â†’ Consultas â†’ Ollama â†’ Respuestas
```

| Componente | TecnologÃ­a | Puerto |
|------------|------------|--------|
| **Vector DB** | Weaviate | 8080 |
| **LLM Local** | Ollama | 11434 |
| **Embeddings** | llama3.1 | - |
| **Chat** | Python CLI | - |

## ğŸ“‹ Requisitos

- **Python** 3.11+
- **Docker Desktop** (para Weaviate)
- **Ollama** (para LLMs locales)
- **8GB RAM** mÃ­nimo

## âš¡ InstalaciÃ³n RÃ¡pida

### 1. Instalar dependencias Python
```bash
pip install weaviate-client==4.16.10 pypdf requests
```

### 2. Instalar Ollama
```bash
# Descargar desde: https://ollama.ai/download
ollama pull llama3.1
ollama pull gemma3:1b
```

### 3. Iniciar servicios
```bash
# Terminal 1: Ollama
ollama serve

# Terminal 2: Weaviate (Docker)
docker-compose up -d
```

### 4. Procesar datos
```bash
python main.py
```

### 5. Â¡Usar el chat interactivo!
```bash
python chat_interactivo.py
```

**Â¡Ahora puedes hacer preguntas como:**
- `"RecomiÃ©ndame un viaje familiar con rating alto"`
- `"Â¿QuÃ© destinos son mejores para aventura?"`
- `"Busco algo romÃ¡ntico para mi pareja"`
- `"Â¿CuÃ¡l es el viaje con mejor rating?"`

## ğŸš€ Uso

### ğŸ’¬ Chat Interactivo (Â¡Recomendado!)
```bash
python chat_interactivo.py
```

**Una vez iniciado el chat, puedes hacer consultas como:**

#### Consultas por Tipo de Viaje:
```
ğŸ” Tu pregunta: "Busco un viaje romÃ¡ntico"
ğŸ” Tu pregunta: "Â¿QuÃ© aventuras hay disponibles?"
ğŸ” Tu pregunta: "RecomiÃ©ndame algo familiar"
```

#### Consultas por Rating/Calidad:
```
ğŸ” Tu pregunta: "Â¿CuÃ¡l es el viaje con mejor rating?"
ğŸ” Tu pregunta: "MuÃ©strame opciones con rating mayor a 4"
ğŸ” Tu pregunta: "Â¿QuÃ© destino tiene las mejores calificaciones?"
```

#### Consultas por CaracterÃ­sticas:
```
ğŸ” Tu pregunta: "Â¿QuÃ© viajes duran mÃ¡s de una semana?"
ğŸ” Tu pregunta: "Busco algo que se pueda hacer en auto"
ğŸ” Tu pregunta: "Â¿CuÃ¡les son los destinos mÃ¡s populares?"
```

**ğŸ’¡ Tip:** Escribe `"salir"` para terminar el chat.

### Uso ProgramÃ¡tico
```python
from clusteConection import get_weaviate_client
from rag_query import query_rag

client = get_weaviate_client()
respuesta = query_rag(client, "Â¿CuÃ¡l es el mejor destino?")
print(respuesta)
```

## ğŸ“ Estructura del Proyecto

```
Weaviable/
â”œâ”€â”€ ğŸ® chat_interactivo.py        # â­ Interfaz principal (Â¡Ãšsalo para hacer preguntas!)
â”œâ”€â”€ ğŸ”§ main.py                    # Procesamiento inicial de datos
â”œâ”€â”€ ğŸ”Œ clusteConection.py         # ConexiÃ³n a Weaviate local (sin autenticaciÃ³n)
â”œâ”€â”€ ğŸ“„ pdfs.py                    # Procesamiento PDF
â”œâ”€â”€ ğŸ§  embeddings.py              # GeneraciÃ³n embeddings con Ollama
â”œâ”€â”€ ğŸ“¤ subir_chunks.py            # Carga de datos vectoriales
â”œâ”€â”€ ğŸ” rag_query.py               # Sistema de consultas RAG
â”œâ”€â”€ ğŸ³ docker-compose.yml         # ConfiguraciÃ³n Weaviate local
â””â”€â”€ ğŸ“š docs/                      # DocumentaciÃ³n completa
```

## ğŸ¯ Flujo de Uso para Estudiantes

### Primera vez (Setup completo):
```bash
# 1. Instalar dependencias
pip install weaviate-client==4.16.10 pypdf requests

# 2. Descargar Ollama y modelos
ollama pull llama3.1

# 3. Iniciar servicios (en terminales separados)
ollama serve
docker-compose up -d

# 4. Procesar datos inicial
python main.py

# 5. Â¡Empezar a hacer preguntas!
python chat_interactivo.py
```

### Uso normal (servicios ya configurados):
```bash
# 1. Iniciar servicios
ollama serve
docker-compose up -d

# 2. Â¡Chat directo!
python chat_interactivo.py
```

## ğŸ’¡ Ejemplos de Consultas

### Por Tipo de Viaje
```
"Busco un viaje romÃ¡ntico"
"Â¿QuÃ© aventuras hay disponibles?"
"RecomiÃ©ndame algo familiar"
```

### Por Rating/Calidad
```
"Â¿CuÃ¡l es el viaje con mejor rating?"
"MuÃ©strame opciones con rating mayor a 4"
"Â¿QuÃ© destino tiene las mejores calificaciones?"
```

### Por CaracterÃ­sticas
```
"Â¿QuÃ© viajes duran mÃ¡s de una semana?"
"Busco algo que se pueda hacer en auto"
"Â¿CuÃ¡les son los destinos mÃ¡s populares?"
```

## ğŸ”§ Troubleshooting

### âŒ Error "Connection refused"
```bash
# Verificar servicios
docker-compose ps
ollama list

# Reiniciar
docker-compose restart
```

### âŒ "No se encontraron documentos"
```bash
# Diagnosticar
python diagnostico.py

# Recargar datos
python limpiar_datos.py
python main.py
```

### âŒ Error de modelo Ollama
```bash
# Verificar modelos
ollama list

# Descargar si falta
ollama pull llama3.1
```

## ğŸ“Š Performance

| MÃ©trica | Valor |
|---------|-------|
| **Tiempo de respuesta** | ~10-30 segundos |
| **Procesamiento PDF** | ~30 seg/MB |
| **Dimensiones embedding** | 4096 |
| **PrecisiÃ³n bÃºsqueda** | ~85-90% |

## ğŸ“– DocumentaciÃ³n Completa

- ğŸ“š [**GuÃ­a Completa para Estudiantes**](GUIA_COMPLETA_ESTUDIANTES.md) - Tutorial paso a paso completo
- ğŸ”„ [**GuÃ­a de Reinicio**](GUIA_REINICIO.md) - CÃ³mo reiniciar el sistema
- ğŸ—ï¸ [**Estructura del Proyecto**](ESTRUCTURA_PROYECTO.md) - Arquitectura detallada

## ğŸš€ Quick Start para Estudiantes

### ğŸ¯ **Â¿Primera vez? (Setup completo)**
```bash
ollama serve â†’ docker-compose up -d â†’ python main.py â†’ python chat_interactivo.py
```

### âš¡ **Â¿Ya tienes datos? (Uso normal)**
```bash
ollama serve â†’ docker-compose up -d â†’ python chat_interactivo.py
```

### ğŸ†˜ **Â¿Problemas?**
```bash
python diagnostico.py
```

### ğŸ’¬ **Una vez en el chat, prueba preguntas como:**
- `"RecomiÃ©ndame un viaje familiar"`
- `"Â¿CuÃ¡l tiene el mejor rating?"`
- `"Busco aventuras en montaÃ±a"`
- `"Â¿QuÃ© destinos duran una semana?"`

## ğŸ¤ Contribuir

1. Fork el repo
2. Crea tu branch (`git checkout -b feature/nueva-funcionalidad`)
3. Commit (`git commit -m 'Agrega nueva funcionalidad'`)
4. Push (`git push origin feature/nueva-funcionalidad`)
5. Abre un Pull Request

## ğŸ“ Changelog

### v1.0.0 (2025-09-25)
- âœ… Sistema RAG completo
- âœ… Chat interactivo
- âœ… BÃºsqueda hÃ­brida
- âœ… Docker local
- âœ… GuÃ­as completas

## ğŸ™ CrÃ©ditos

- [Weaviate](https://weaviate.io/) - Vector database
- [Ollama](https://ollama.ai/) - Local LLMs
- [PyPDF](https://pypdf.readthedocs.io/) - PDF processing

## ğŸ“„ Licencia

MIT License - ver [LICENSE](LICENSE) para detalles.

---

<div align="center">

**â­ Â¿Te gusta el proyecto? Â¡Dale una estrella!**

[ğŸ› Reportar Bug](https://github.com/tu-usuario/weaviable/issues) â€¢ [âœ¨ Pedir Feature](https://github.com/tu-usuario/weaviable/issues) â€¢ [ğŸ“– DocumentaciÃ³n](docs/)

**Hecho con â¤ï¸ usando Python, Weaviate y Ollama**

</div>

